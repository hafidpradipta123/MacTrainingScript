{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "nnfs.init()\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "nnfs.init()\n",
    "# Dense layer\n",
    "class Layer_Dense :\n",
    "# Layer initialization\n",
    "    def __init__ ( self , n_inputs , n_neurons , weight_regularizer_l1 = 0, weight_regularizer_l2 = 0, bias_regularizer_l1 = 0, bias_regularizer_l2 =0):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros(( 1 , n_neurons))\n",
    "        self.weight_regularizer_l1 = weight_regularizer_l1\n",
    "        self.weight_regularizer_l2 = weight_regularizer_l2\n",
    "        self.bias_regularizer_l1 = bias_regularizer_l1\n",
    "        self.bias_regularizer_l2 = bias_regularizer_l2\n",
    "        #set regularization strength\n",
    "    # Forward pass\n",
    "    def forward ( self , inputs ):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "    # Backward pass\n",
    "    def backward ( self , dvalues ):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis = 0 , keepdims = True )\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "        #Gradients on regularization\n",
    "        #L1 on weights\n",
    "\n",
    "        if self.weight_regularizer_l1 >0:\n",
    "            dL1 = np.ones_like(self.weights)\n",
    "            dL1[self.weights <0 ] =-1\n",
    "            self.dweights += self.weight_regularizer_l1 * dL1\n",
    "        #l2 on weights\n",
    "        if self.weight_regularizer_l2 >0:\n",
    "            self.dweights += 2*self.weight_regularizer_l2 * self.weights\n",
    "\n",
    "        #L1 regularization - biases\n",
    "\n",
    "        if self.bias_regularizer_l1 > 0:\n",
    "            dL1 = np.ones_like(self.biases)\n",
    "            dL1[self.biases< 0 ] = -1\n",
    "            self.dbiases += self.bias_regularizer_l1 * dL1\n",
    "\n",
    "        #l2 on biases\n",
    "        if self.bias_regularizer_l2> 0:\n",
    "            self.dbiases +=  2 * self.bias_regularizer_l2 * self.biases\n",
    "        #Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "    # ReLU activation\n",
    "class Activation_ReLU :\n",
    "    # Forward pass\n",
    "    def forward ( self , inputs ):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum( 0 , inputs)\n",
    "        # Backward pass\n",
    "    def backward ( self , dvalues ):\n",
    "        # Since we need to modify original variable,\n",
    "        # let's make a copy of values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "        # Zero gradient where input values were negative\n",
    "        self.dinputs[self.inputs <= 0 ] = 0\n",
    "    # Softmax activation\n",
    "class Activation_Softmax :\n",
    "    # Forward pass\n",
    "    def forward ( self , inputs ):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis = 1 ,\n",
    "        keepdims = True ))\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis = 1 ,\n",
    "        keepdims = True )\n",
    "        self.output = probabilities\n",
    "        # Backward pass\n",
    "    def backward ( self , dvalues ):\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in \\\n",
    "        enumerate ( zip (self.output, dvalues)):\n",
    "        # Flatten output array\n",
    "            single_output = single_output.reshape( - 1 , 1 )\n",
    "            # Calculate Jacobian matrix of the output and\n",
    "            jacobian_matrix = np.diagflat(single_output) - \\\n",
    "            np.dot(single_output, single_output.T)\n",
    "            # Calculate sample-wise gradient\n",
    "            # and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
    "            single_dvalues)\n",
    "\n",
    "\n",
    "# Common loss class\n",
    "class Loss :\n",
    "\n",
    "    #Regularization on loss calculation\n",
    "\n",
    "    def regularization_loss(self, layer):\n",
    "        #0 by default\n",
    "\n",
    "        regularization_loss = 0\n",
    "        #L1 regularization-weights\n",
    "        #calculate only when factor greater than 0\n",
    "        #L1 regularization’s penalty is the sum of all the absolute values for the weights and biases.\n",
    "        #This is a linear penalty as regularization loss returned by this function is directly proportional to\n",
    "        #parameter values. L2 regularization’s penalty is the sum of the squared weights and biases.\n",
    "\n",
    "\n",
    "        if layer.weight_regularizer_l1 > 0:\n",
    "            regularization_loss += layer.weight_regularizer_l1 * np.sum(np.abs(layer.weights))\n",
    "\n",
    "        #L2 regularization - weights\n",
    "        if layer.weight_regularizer_l2 > 0:\n",
    "            regularization_loss += layer.weight_regularizerl2 * np.sum(layer.weights*layer.weights)\n",
    "\n",
    "        #L1 regularization - biases\n",
    "        #calculate only when factor greater than 0\n",
    "        if layer.bias_regularizer_l1 > 0:\n",
    "            regularization_loss += layer.bias_regularizer_l1 * np.sum(np.abs(layer.biases))\n",
    "\n",
    "        #L2 regularization - biases\n",
    "        if layer.bias_regularizer_l2 > 0:\n",
    "            regularization_loss += layer.bias_regularizer_l2 * np.sum(layer.biases * layer.biases)\n",
    "\n",
    "        return regularization_loss       \n",
    "\n",
    "        \n",
    "    # Calculates the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate ( self , output , y ):\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        # Return loss\n",
    "        return data_loss\n",
    "        # Cross-entropy loss\n",
    "\n",
    "\n",
    "\n",
    "class Loss_CategoricalCrossentropy ( Loss ):\n",
    "    # Forward pass\n",
    "    def forward ( self , y_pred , y_true ):\n",
    "    # Number of samples in a batch\n",
    "        samples = len (y_pred)\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7 , 1 - 1e-7 )\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len (y_true.shape) == 1 :\n",
    "            correct_confidences = y_pred_clipped[\n",
    "            range (samples),\n",
    "            y_true\n",
    "            ]\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len (y_true.shape) == 2 :\n",
    "            correct_confidences = np.sum(\n",
    "            y_pred_clipped * y_true,\n",
    "            axis = 1\n",
    "            )\n",
    "    # Losses\n",
    "        negative_log_likelihoods = - np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "        # Backward pass\n",
    "    def backward ( self , dvalues , y_true ):\n",
    "        # Number of samples\n",
    "        samples = len (dvalues)\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len (dvalues[ 0 ])\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len (y_true.shape) == 1 :\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        # Calculate gradient\n",
    "        self.dinputs = - y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "        \n",
    "        # Softmax classifier - combined Softmax activation\n",
    "# and cross-entropy loss for faster backward step\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy ():\n",
    "    # Creates activation and loss function objects\n",
    "    def __init__ ( self ):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "        # Forward pass\n",
    "    def forward ( self , inputs , y_true ):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "        # Calculate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "    # Backward pass\n",
    "    def backward ( self , dvalues , y_true ):\n",
    "        # Number of samples\n",
    "        samples = len (dvalues)\n",
    "        # If labels are one-hot encoded,\n",
    "        # turn them into discrete values\n",
    "        if len (y_true.shape) == 2 :\n",
    "            y_true = np.argmax(y_true, axis = 1 )\n",
    "            # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "        # Calculate gradient\n",
    "        self.dinputs[ range (samples), y_true] -= 1\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "class Basic_SGD:\n",
    "\n",
    "    def __init__(self, learning_rate = 1.0):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "\n",
    "    def update_params(self, layer):\n",
    "        layer.weights += -self.learning_rate * layer.dweights\n",
    "        layer.biases += -self.learning_rate * layer.dbiases\n",
    "\n",
    "class Optimizer_SGD:\n",
    "    #Initialize optimizer - set settings,\n",
    "    #learning rate of 1 is default for this optimizer\n",
    "\n",
    "    def __init__(self, learning_rate = 1, decay = 0, momentum = 0):\n",
    "        self.name = \"optimizerSGD\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    def update_params(self, layer):\n",
    "        #if later does not contain momentum arrays, create them\n",
    "        #filled them with zeros\n",
    "        if self.momentum:\n",
    "\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                #if there is no momentum array for weights\n",
    "                #the array does not exist for biases yet either\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "\n",
    "            #Build weight updates with momentum - take previous\n",
    "            #updates multiplied by retain factor and update with\n",
    "            #current gradients\n",
    "\n",
    "            weight_updates = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "\n",
    "            #build bias updates\n",
    "            bias_updates = self.momentum * layer.bias_momentums - self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentum = bias_updates\n",
    "            \n",
    "        else:\n",
    "            weight_updates = -self.current_learning_rate * layer.dweights\n",
    "            bias_updates = -self.current_learning_rate * layer.dbiases\n",
    "\n",
    "\n",
    "        layer.weights += -self.learning_rate * layer.dweights\n",
    "        layer.biases += -self.learning_rate * layer.dbiases\n",
    "\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "# Adagrad optimizer\n",
    "class Optimizer_Adagrad :\n",
    "    # Initialize optimizer - set settings\n",
    "    def __init__ ( self , learning_rate = 1. , decay = 0. , epsilon = 1e-7 ):\n",
    "        self.name = \"OptimizerAdagrad\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params ( self ):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate *  ( 1. / ( 1. + self.decay * self.iterations))\n",
    "        \n",
    "    # Update parameters\n",
    "    def update_params ( self , layer ):\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr (layer, 'weight_cache' ):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache += layer.dweights ** 2\n",
    "        layer.bias_cache += layer.dbiases ** 2\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += - self.current_learning_rate * layer.dweights /  (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += - self.current_learning_rate *  layer.dbiases /       (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "        # Call once after any parameter updates\n",
    "    def post_update_params ( self ):\n",
    "        self.iterations += 1\n",
    "\n",
    "class Optimizer_RMSprop:\n",
    "\n",
    "    def __init__(self, learning_rate = 0.001, decay = 0, epsilon = 1e-7, rho=0.9):\n",
    "        self.name = \"RMSProp\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.rho = rho\n",
    "    \n",
    "    #Update parameters\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "    \n",
    "    def update_params(self, layer):\n",
    "\n",
    "        #if layer does not contain cache arrays\n",
    "        #create them filled with zeros\n",
    "\n",
    "        if not hasattr(layer, 'weight_cache'): \n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        #update cache with squared current gradient\n",
    "        layer.weight_cache = self.rho * layer.weight_cache + (1 - self.rho) * layer.dweights ** 2\n",
    "        layer.bias_cache =  self.rho * layer.bias_cache + (1 - self.rho) * layer.dbiases ** 2\n",
    "\n",
    "        layer.weights += - self.current_learning_rate * layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += - self.current_learning_rate * layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "    \n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "class Optimizer_Adam:\n",
    "\n",
    "    def __init__(self, learning_rate = 0.001, decay = 0, epsilon = 1e-7, beta_1 = 0.9, beta_2 = 0.999):\n",
    "        self.name = \"OptimizerAdam\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.epsilon = epsilon\n",
    "        self.iterations = 0\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "    \n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        #if layer does not contain cache arrays\n",
    "        #create them filled with zeros\n",
    "\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "            \n",
    "\n",
    "        layer.weight_momentums = self.beta_1 * layer.weight_momentums  + (1- self.beta_1) * layer.dweights\n",
    "        layer.bias_momentums = self.beta_1 * layer.bias_momentums + (1- self.beta_1) * layer.dbiases\n",
    "\n",
    "        weight_momentums_corrected = layer.weight_momentums / ( 1 - self.beta_1 ** (self.iterations + 1 ))\n",
    "        bias_momentums_corrected = layer.bias_momentums / ( 1 - self.beta_1 ** (self.iterations + 1 ))\n",
    "# Update cache with squared current gradients\n",
    "        layer.weight_cache = self.beta_2 * layer.weight_cache + ( 1 - self.beta_2) * layer.dweights ** 2\n",
    "        layer.bias_cache = self.beta_2 * layer.bias_cache + ( 1 - self.beta_2) * layer.dbiases ** 2\n",
    "\n",
    "        weight_cache_corrected = layer.weight_cache / ( 1 - self.beta_2 ** (self.iterations + 1 ))\n",
    "        bias_cache_corrected = layer.bias_cache / ( 1 - self.beta_2 ** (self.iterations + 1 ))\n",
    "\n",
    "        layer.weights += - self.current_learning_rate * weight_momentums_corrected / (np.sqrt(weight_cache_corrected) + self.epsilon)\n",
    "        layer.biases += - self.current_learning_rate * bias_momentums_corrected / (np.sqrt(bias_cache_corrected) + self.epsilon)\n",
    "    \n",
    "    def post_update_params ( self ):\n",
    "        self.iterations += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = spiral_data( samples = 100 , classes = 3 )\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense( 2 , 64 , weight_regularizer_l1=5e-4, bias_regularizer_l2= 5e-4)\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "\n",
    "activation1 = Activation_ReLU()\n",
    "# Create second Dense layer with 3 input features (as we take output\n",
    "# of previous layer here) and 3 output values (output values)\n",
    "\n",
    "dense2 = Layer_Dense( 64 ,3  )\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Perform a forward pass of our training data through this layer\n",
    "optimizer_class =[ \n",
    "Optimizer_Adagrad(decay = 1e-4),\n",
    "Optimizer_SGD(decay = 1e-3, momentum = 0.9),\n",
    "Optimizer_RMSprop( decay = 1e-4 ),\n",
    "Optimizer_RMSprop( learning_rate = 0.02 , decay = 1e-5 ,rho = 0.999 ),\n",
    "Optimizer_Adam( learning_rate = 0.02 , decay = 1e-5 )]\n",
    "\n",
    "scores = {\"method\":[],\"epoch\":[],\"loss\":[],\"lr\":[],\"acc\":[], \"reg_loss\":[],\"data_loss\":[]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 , acc: 0.360 , loss: 1.099 data_loss: 1.099 , reg_loss: 0.001 , lr: 1.0 method: OptimizerAdagrad\n",
      "epoch: 5000 , acc: 0.743 , loss: 0.646 data_loss: 0.584 , reg_loss: 0.062 , lr: 0.6667111140742716 method: OptimizerAdagrad\n",
      "epoch: 10000 , acc: 0.780 , loss: 0.594 data_loss: 0.529 , reg_loss: 0.065 , lr: 0.5000250012500626 method: OptimizerAdagrad\n",
      "epoch: 0 , acc: 0.780 , loss: 0.594 data_loss: 0.529 , reg_loss: 0.065 , lr: 1 method: optimizerSGD\n",
      "epoch: 5000 , acc: 0.597 , loss: 0.844 data_loss: 0.790 , reg_loss: 0.054 , lr: 0.16669444907484582 method: optimizerSGD\n",
      "epoch: 10000 , acc: 0.607 , loss: 0.797 data_loss: 0.728 , reg_loss: 0.069 , lr: 0.09091735612328393 method: optimizerSGD\n",
      "epoch: 0 , acc: 0.600 , loss: 0.798 data_loss: 0.729 , reg_loss: 0.069 , lr: 0.001 method: RMSProp\n",
      "epoch: 5000 , acc: 0.863 , loss: 0.447 data_loss: 0.361 , reg_loss: 0.086 , lr: 0.0006667111140742717 method: RMSProp\n",
      "epoch: 10000 , acc: 0.900 , loss: 0.383 data_loss: 0.290 , reg_loss: 0.094 , lr: 0.0005000250012500625 method: RMSProp\n",
      "epoch: 0 , acc: 0.907 , loss: 0.383 data_loss: 0.290 , reg_loss: 0.094 , lr: 0.02 method: RMSProp\n",
      "epoch: 5000 , acc: 0.903 , loss: 0.318 data_loss: 0.209 , reg_loss: 0.108 , lr: 0.01904780045524243 method: RMSProp\n",
      "epoch: 10000 , acc: 0.930 , loss: 0.292 data_loss: 0.184 , reg_loss: 0.108 , lr: 0.018181983472577025 method: RMSProp\n",
      "epoch: 0 , acc: 0.920 , loss: 0.285 data_loss: 0.177 , reg_loss: 0.108 , lr: 0.02 method: OptimizerAdam\n",
      "epoch: 5000 , acc: 0.967 , loss: 0.199 data_loss: 0.120 , reg_loss: 0.079 , lr: 0.01904780045524243 method: OptimizerAdam\n",
      "epoch: 10000 , acc: 0.970 , loss: 0.162 data_loss: 0.098 , reg_loss: 0.064 , lr: 0.018181983472577025 method: OptimizerAdam\n"
     ]
    }
   ],
   "source": [
    "for  optimizer in optimizer_class: \n",
    "    \n",
    "    for epoch in range (10001):\n",
    "        \n",
    "\n",
    "        dense1.forward(X)\n",
    "        #this is whhen input * weight + bias\n",
    "        # Perform a forward pass through activation function\n",
    "        # takes the output of first dense layer here\n",
    "\n",
    "        activation1.forward(dense1.output) #this is relu\n",
    "        # Perform a forward pass through second Dense layer\n",
    "        # takes outputs of activation function of first layer as inputs\n",
    "\n",
    "        dense2.forward(activation1.output) #this is input * weight + bias\n",
    "        # Perform a forward pass through the activation/loss function\n",
    "        # takes the output of second dense layer here and returns loss\n",
    "\n",
    "        data_loss = loss_activation.forward(dense2.output, y)\n",
    "        \n",
    "        #calculate regularization penalty\n",
    "\n",
    "        regularization_loss = loss_activation.loss.regularization_loss(dense1) + loss_activation.loss.regularization_loss(dense2)\n",
    "\n",
    "        #calculate overall loss\n",
    "        loss = data_loss + regularization_loss\n",
    "\n",
    "        predictions = np.argmax(loss_activation.output, axis = 1 )\n",
    "        if len (y.shape) == 2 :\n",
    "            y = np.argmax(y, axis = 1 )\n",
    "        accuracy = np.mean(predictions == y)\n",
    "\n",
    "        if not epoch % 5000:\n",
    "        \n",
    "\n",
    "            print(f'epoch: {epoch} , ' +\n",
    "                    f'acc: {accuracy :.3f} , ' +\n",
    "                    f'loss: {loss :.3f} ' +\n",
    "                    f'data_loss: {data_loss :.3f} , ' +\n",
    "                    f'reg_loss: {regularization_loss :.3f} , ' +\n",
    "                    f'lr: {optimizer.current_learning_rate} ' +\n",
    "                    f'method: {optimizer.name}')\n",
    "\n",
    "            scores[\"method\"].append(optimizer.name)\n",
    "            scores[\"epoch\"].append(epoch)\n",
    "            scores[\"acc\"].append(accuracy)\n",
    "            scores[\"loss\"].append(loss)\n",
    "            scores[\"data_loss\"].append(data_loss)\n",
    "            scores[\"reg_loss\"].append(regularization_loss)\n",
    "            scores[\"lr\"].append(optimizer.current_learning_rate)       \n",
    "\n",
    "\n",
    "        # Backward pass\n",
    "        loss_activation.backward(loss_activation.output, y)\n",
    "        dense2.backward(loss_activation.dinputs)\n",
    "        activation1.backward(dense2.dinputs)\n",
    "        dense1.backward(activation1.dinputs)\n",
    "\n",
    "            \n",
    "        optimizer.pre_update_params()\n",
    "        optimizer.update_params(dense1)\n",
    "        optimizer.update_params(dense2)\n",
    "        optimizer.post_update_params()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>acc</th>\n",
       "      <th>reg_loss</th>\n",
       "      <th>data_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OptimizerAdagrad</td>\n",
       "      <td>0</td>\n",
       "      <td>1.099095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.098594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OptimizerAdagrad</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.645967</td>\n",
       "      <td>0.666711</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>0.062360</td>\n",
       "      <td>0.583607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OptimizerAdagrad</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.594087</td>\n",
       "      <td>0.500025</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.064821</td>\n",
       "      <td>0.529266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>optimizerSGD</td>\n",
       "      <td>0</td>\n",
       "      <td>0.593893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.064811</td>\n",
       "      <td>0.529082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>optimizerSGD</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.844198</td>\n",
       "      <td>0.166694</td>\n",
       "      <td>0.596667</td>\n",
       "      <td>0.054026</td>\n",
       "      <td>0.790172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>optimizerSGD</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.796557</td>\n",
       "      <td>0.090917</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.068960</td>\n",
       "      <td>0.727597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RMSProp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.798036</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.068923</td>\n",
       "      <td>0.729113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RMSProp</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.446535</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.085515</td>\n",
       "      <td>0.361020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RMSProp</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.383417</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.093591</td>\n",
       "      <td>0.289826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RMSProp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383395</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.093596</td>\n",
       "      <td>0.289799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RMSProp</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.317729</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.108267</td>\n",
       "      <td>0.209463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RMSProp</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.292048</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.107987</td>\n",
       "      <td>0.184062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OptimizerAdam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285259</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.108030</td>\n",
       "      <td>0.177229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OptimizerAdam</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.199294</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.079461</td>\n",
       "      <td>0.119833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OptimizerAdam</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.161888</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.064349</td>\n",
       "      <td>0.097539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              method  epoch      loss        lr       acc  reg_loss  data_loss\n",
       "0   OptimizerAdagrad      0  1.099095  1.000000  0.360000  0.000500   1.098594\n",
       "1   OptimizerAdagrad   5000  0.645967  0.666711  0.743333  0.062360   0.583607\n",
       "2   OptimizerAdagrad  10000  0.594087  0.500025  0.780000  0.064821   0.529266\n",
       "3       optimizerSGD      0  0.593893  1.000000  0.780000  0.064811   0.529082\n",
       "4       optimizerSGD   5000  0.844198  0.166694  0.596667  0.054026   0.790172\n",
       "5       optimizerSGD  10000  0.796557  0.090917  0.606667  0.068960   0.727597\n",
       "6            RMSProp      0  0.798036  0.001000  0.600000  0.068923   0.729113\n",
       "7            RMSProp   5000  0.446535  0.000667  0.863333  0.085515   0.361020\n",
       "8            RMSProp  10000  0.383417  0.000500  0.900000  0.093591   0.289826\n",
       "9            RMSProp      0  0.383395  0.020000  0.906667  0.093596   0.289799\n",
       "10           RMSProp   5000  0.317729  0.019048  0.903333  0.108267   0.209463\n",
       "11           RMSProp  10000  0.292048  0.018182  0.930000  0.107987   0.184062\n",
       "12     OptimizerAdam      0  0.285259  0.020000  0.920000  0.108030   0.177229\n",
       "13     OptimizerAdam   5000  0.199294  0.019048  0.966667  0.079461   0.119833\n",
       "14     OptimizerAdam  10000  0.161888  0.018182  0.970000  0.064349   0.097539"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.DataFrame(data = scores)\n",
    "df_scores"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24e68ee5c3be1453adda2c12808546301ced8adfec32f06d9e3ee889c2d5adb6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('ve1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
