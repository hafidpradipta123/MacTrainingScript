{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class Layer_Dense:\n",
    "\n",
    "    #layer initialization \n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        #calculate output values form inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "class Activation_ReLU:\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class Activation_Softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis = 1, keepdims = True))\n",
    "\n",
    "        #normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis = 1, keepdims = True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "#common loss class\n",
    "class loss:\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output,y)\n",
    "\n",
    "        data_loss= np.mean(sample_losses)\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "class Loss_CategoricalCrossentropy(loss):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        if len (y_true.shape) == 1:\n",
    "            correct_confidences  = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped * y_true,\n",
    "                axis = 1\n",
    "            )\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = spiral_data(samples = 100, classes  =3)\n",
    "dense1 = Layer_Dense(2,3)\n",
    "activation1 = Activation_ReLU()\n",
    "dense2 = Layer_Dense(3,3)\n",
    "activation2 = Activation_Softmax()\n",
    "loss_function = Loss_CategoricalCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_loss = 9999999\n",
    "best_dense1_weights = dense1.weights.copy()\n",
    "best_dense1_biases = dense1.biases.copy()\n",
    "best_dense2_weights = dense2.weights.copy()\n",
    "best_dense2_biases = dense2.biases.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new set of weights found, iteration: 0 loss: 1.1008568 acc: 0.3333333333333333\n",
      "new set of weights found, iteration: 1 loss: 1.0990819 acc: 0.3333333333333333\n",
      "new set of weights found, iteration: 3 loss: 1.098629 acc: 0.3333333333333333\n",
      "new set of weights found, iteration: 11 loss: 1.0985013 acc: 0.3333333333333333\n",
      "new set of weights found, iteration: 58 loss: 1.0984759 acc: 0.36666666666666664\n",
      "new set of weights found, iteration: 87 loss: 1.0984341 acc: 0.3933333333333333\n",
      "new set of weights found, iteration: 389 loss: 1.0983855 acc: 0.3333333333333333\n",
      "new set of weights found, iteration: 602 loss: 1.0983611 acc: 0.3433333333333333\n",
      "new set of weights found, iteration: 812 loss: 1.0983337 acc: 0.3333333333333333\n",
      "new set of weights found, iteration: 1765 loss: 1.0982677 acc: 0.37\n",
      "new set of weights found, iteration: 3766 loss: 1.0980942 acc: 0.3333333333333333\n",
      "new set of weights found, iteration: 3979 loss: 1.0980837 acc: 0.3333333333333333\n",
      "new set of weights found, iteration: 5582 loss: 1.0980535 acc: 0.3466666666666667\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10000):\n",
    "    dense1.weights = 0.05 * np.random.randn(2,3)\n",
    "    dense1.biases = 0.05 * np.random.randn(1,3)\n",
    "    dense2.weights = 0.05 * np.random.randn(3,3)\n",
    "    dense2.biases = 0.05 * np.random.randn(1,3)\n",
    "\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    activation2.forward(dense2.output)\n",
    "\n",
    "    loss = loss_function.calculate(activation2.output,y)\n",
    "\n",
    "    predictions = np.argmax(activation2.output, axis = 1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "    \n",
    "\n",
    "    #if loss is smaller - print and save weights and biases aside\n",
    "    if loss < lowest_loss:\n",
    "        print(\"new set of weights found, iteration:\", iteration, \"loss:\", loss, \"acc:\", accuracy)\n",
    "\n",
    "        best_dense1_weights = dense1.weights.copy()\n",
    "        best_dense1_biases = dense1.biases.copy()\n",
    "        best_dense2_weights = dense1.weights.copy()\n",
    "        best_dense2_boases = dense1.biases.copy()\n",
    "        lowest_loss = loss\n",
    "    else:\n",
    "        dense1.weights = best_dense1_weights.copy()\n",
    "        dense1.biases = best_dense1_biases.copy()\n",
    "        dense2.weights = best_dense2_weights.copy()\n",
    "        dense2.biases = best_dense2_biases.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0 1.0 1.0 1.0\n",
      "-3.0 1.0 -1.0 -2.0 2.0 3.0\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "x = [ 1.0 , - 2.0 , 3.0 ] # input values\n",
    "w = [ - 3.0 , - 1.0 , 2.0 ] # weights\n",
    "b = 1.0 # bias\n",
    "\n",
    "# Multiplying inputs by weights\n",
    "xw0 = x[ 0 ] * w[ 0 ]\n",
    "xw1 = x[ 1 ] * w[ 1 ]\n",
    "xw2 = x[ 2 ] * w[ 2 ]\n",
    "# Adding weighted inputs and a bias\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "# ReLU activation function\n",
    "y = max (z, 0 )\n",
    "# Backward pass\n",
    "# The derivative from the next layer\n",
    "dvalue = 1.0 \n",
    "# Derivative of ReLU and the chain rule\n",
    "drelu_dz = dvalue * ( 1. if z > 0 else 0. )\n",
    "print (drelu_dz)\n",
    "\n",
    "dsum_dxw0 = 1 #derivative of the sum with respect of x[0]w[0] #what is derivative of f(x+y+z+l+m+o) with respect of x? must be 1\n",
    "dsum_dxw1 = 1\n",
    "dsum_dxw2 = 1\n",
    "dsum_db = 1 # bias is a vector. derivative is one\n",
    "drelu_dxw0 = drelu_dz * dsum_dxw0\n",
    "drelu_dxw1 = drelu_dz * dsum_dxw1\n",
    "drelu_dxw2 = drelu_dz * dsum_dxw2\n",
    "drelu_db = drelu_dz * dsum_db\n",
    "print(drelu_dxw0, drelu_dxw1, drelu_dxw2, drelu_db)\n",
    "\n",
    "dmul_dx0 = w[0] #partial derivative of a function multiplicaiton. What is the derivative of f(X * y * z) with the respect of X? it will be everything without the X \n",
    "dmul_dx1 = w[1]\n",
    "dmul_dx2 = w[2]\n",
    "dmul_dw0 = x[0]\n",
    "dmul_dw1 = x[1]\n",
    "dmul_dw2 = x[2]\n",
    "\n",
    "drelu_dx0 = drelu_dxw0 * dmul_dx0\n",
    "drelu_dw0 = drelu_dxw0 * dmul_dw0\n",
    "drelu_dx1 = drelu_dxw1 * dmul_dx1\n",
    "drelu_dw1 = drelu_dxw1 * dmul_dw1\n",
    "drelu_dx2 = drelu_dxw2 * dmul_dx2\n",
    "drelu_dw2 = drelu_dxw2 * dmul_dw2\n",
    "print (drelu_dx0, drelu_dw0, drelu_dx1, drelu_dw1, drelu_dx2, drelu_dw2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.0, -1.0, 2.0] 1.0\n"
     ]
    }
   ],
   "source": [
    "print(w,b)\n",
    "dx = [drelu_dx0, drelu_dx1, drelu_dx2] # gradients on inputs\n",
    "dw = [drelu_dw0, drelu_dw1, drelu_dw2] # gradients on weights\n",
    "db = drelu_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.001, -0.998, 1.997] 0.999\n"
     ]
    }
   ],
   "source": [
    "w[0] += -0.001 * dw[0]\n",
    "w[1] += -0.001 * dw[1]\n",
    "w[2] += -0.001 * dw[2]\n",
    "b += -0.001 * db\n",
    "print(w,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.985\n"
     ]
    }
   ],
   "source": [
    "xw0 = x[ 0 ] * w[ 0 ]\n",
    "xw1 = x[ 1 ] * w[ 1 ]\n",
    "xw2 = x[ 2 ] * w[ 2 ]\n",
    "\n",
    "# Adding\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "# ReLU activation function\n",
    "y = max (z, 0 )\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2 ,  0.5 , -0.26],\n",
       "       [ 0.8 , -0.91, -0.27],\n",
       "       [-0.5 ,  0.26,  0.17],\n",
       "       [ 1.  , -0.5 ,  0.87]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dvalues = np.array([[1.,1.,1.]])\n",
    "weights = np.array([[ 0.2 , 0.8 , - 0.5 , 1 ],\n",
    "[ 0.5 , - 0.91 , 0.26 , - 0.5 ],\n",
    "[ - 0.26 , - 0.27 , 0.17 , 0.87 ]]).T\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(4, 3)\n",
      "(3,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "print(dvalues.shape)\n",
    "print(weights.shape)\n",
    "print(weights[0].shape)\n",
    "print(dvalues[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44  0.44  0.44]\n",
      " [-0.38 -0.38 -0.38]\n",
      " [-0.07 -0.07 -0.07]\n",
      " [ 1.37  1.37  1.37]]\n"
     ]
    }
   ],
   "source": [
    "dx0 = sum (weights[ 0 ]) * dvalues[ 0 ]\n",
    "dx1 = sum (weights[ 1 ]) * dvalues[ 0 ]\n",
    "dx2 = sum (weights[ 2 ]) * dvalues[ 0 ]\n",
    "dx3 = sum (weights[ 3 ]) * dvalues[ 0 ]\n",
    "dinputs = np.array([dx0, dx1, dx2, dx3])\n",
    "print (dinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44  0.44  0.44]\n",
      " [-0.38 -0.38 -0.38]\n",
      " [-0.07 -0.07 -0.07]\n",
      " [ 1.37  1.37  1.37]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.44, 0.44, 0.44])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# a vector of 1s\n",
    "dvalues = np.array([[ 1. , 1. , 1. ]])\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[ 0.2 , 0.8 , - 0.5 , 1 ],\n",
    "[ 0.5 , - 0.91 , 0.26 , - 0.5 ],\n",
    "[ - 0.26 , - 0.27 , 0.17 , 0.87 ]]).T\n",
    "# sum weights of given input\n",
    "# and multiply by the passed in gradient for this neuron\n",
    "dx0 = sum (weights[ 0 ]) * dvalues[ 0 ]\n",
    "dx1 = sum (weights[ 1 ]) * dvalues[ 0 ]\n",
    "dx2 = sum (weights[ 2 ]) * dvalues[ 0 ]\n",
    "dx3 = sum (weights[ 3 ]) * dvalues[ 0 ]\n",
    "dinputs = np.array([dx0, dx1, dx2, dx3])\n",
    "print (dinputs)\n",
    "dx0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.44 -0.38 -0.07  1.37]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43999999999999995"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# a vector of 1s\n",
    "dvalues = np.array([[ 1. , 1. , 1. ],\n",
    "[ 2. , 2. , 2. ],\n",
    "[ 3. , 3. , 3. ]])\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[ 0.2 , 0.8 , - 0.5 , 1 ],\n",
    "[ 0.5 , - 0.91 , 0.26 , - 0.5 ],\n",
    "[ - 0.26 , - 0.27 , 0.17 , 0.87 ]]).T\n",
    "# sum weights of given input\n",
    "# and multiply by the passed in gradient for this neuron\n",
    "dx0 = sum (weights[ 0 ] * dvalues[ 0 ])\n",
    "dx1 = sum (weights[ 1 ] * dvalues[ 0 ])\n",
    "dx2 = sum (weights[ 2 ] * dvalues[ 0 ])\n",
    "dx3 = sum (weights[ 3 ] * dvalues[ 0 ])\n",
    "dinputs = np.array([dx0, dx1, dx2, dx3])\n",
    "print (dinputs)\n",
    "dx0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44 -0.38 -0.07  1.37]\n",
      " [ 0.88 -0.76 -0.14  2.74]\n",
      " [ 1.32 -1.14 -0.21  4.11]]\n"
     ]
    }
   ],
   "source": [
    "dinputs = np.dot(dvalues[0], weights.T)\n",
    "dinputs2 = np.dot(dvalues, weights.T)\n",
    "print(dinputs2)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2a999898ad509a5045ed7dea1feb70ce46febbdc78e231f5d65242874db573b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ve1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
